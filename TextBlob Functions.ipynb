{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextBlob is a Python (2 and 3) library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Noun phrase extraction\n",
    "* Part-of-speech tagging\n",
    "* Sentiment analysis\n",
    "* Classification (Naive Bayes, Decision Tree)\n",
    "* Tokenization (splitting text into words and sentences)\n",
    "* Word and phrase frequencies\n",
    "* Parsing\n",
    "* n-grams\n",
    "* Word inflection (pluralization and singularization) and lemmatization\n",
    "* Spelling correction\n",
    "* Add new models or languages through extensions\n",
    "* WordNet integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing and download necessary corpora"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install -U textblob\n",
    "python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will install TextBlob and download the necessary NLTK corpora. If you need to change the default download\n",
    "directory set the NLTK_DATA environment variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextBlob aims to provide access to common text-processing operations through a familiar interface. You can treat\n",
    "TextBlob objects as if they were Python strings that learned how to do Natural Language Processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "sf = TextBlob(\"San Francisco, officially the City and County of San Francisco and colloquially known as SF, San Fran, Frisco, or The City,is the cultural, commercial, and financial center of Northern California. San Francisco is the 16th most populous city in the United States, and the fourth most populous in California, with 881,549 residents as of 2019.It covers an area of about 46.89 square miles (121.4 km2),mostly at the north end of the San Francisco Peninsula in the San Francisco Bay Area, making it the second most densely populated large U.S. city, and the fifth most densely populated U.S. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part-of-speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('San', 'NNP'),\n",
       " ('Francisco', 'NNP'),\n",
       " ('officially', 'RB'),\n",
       " ('the', 'DT'),\n",
       " ('City', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('County', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('San', 'NNP'),\n",
       " ('Francisco', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('colloquially', 'RB'),\n",
       " ('known', 'VBN'),\n",
       " ('as', 'IN'),\n",
       " ('SF', 'NNP'),\n",
       " ('San', 'NNP'),\n",
       " ('Fran', 'NNP'),\n",
       " ('Frisco', 'NNP'),\n",
       " ('or', 'CC'),\n",
       " ('The', 'DT'),\n",
       " ('City', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('cultural', 'JJ'),\n",
       " ('commercial', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('financial', 'JJ'),\n",
       " ('center', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Northern', 'NNP'),\n",
       " ('California', 'NNP'),\n",
       " ('San', 'NNP'),\n",
       " ('Francisco', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('16th', 'CD'),\n",
       " ('most', 'JJS'),\n",
       " ('populous', 'JJ'),\n",
       " ('city', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('United', 'NNP'),\n",
       " ('States', 'NNPS'),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('fourth', 'JJ'),\n",
       " ('most', 'RBS'),\n",
       " ('populous', 'JJ'),\n",
       " ('in', 'IN'),\n",
       " ('California', 'NNP'),\n",
       " ('with', 'IN'),\n",
       " ('881,549', 'CD'),\n",
       " ('residents', 'NNS'),\n",
       " ('as', 'IN'),\n",
       " ('of', 'IN'),\n",
       " ('2019.It', 'CD'),\n",
       " ('covers', 'NNS'),\n",
       " ('an', 'DT'),\n",
       " ('area', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('about', 'IN'),\n",
       " ('46.89', 'CD'),\n",
       " ('square', 'JJ'),\n",
       " ('miles', 'NNS'),\n",
       " ('121.4', 'CD'),\n",
       " ('km2', 'NN'),\n",
       " ('mostly', 'RB'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('north', 'JJ'),\n",
       " ('end', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('San', 'NNP'),\n",
       " ('Francisco', 'NNP'),\n",
       " ('Peninsula', 'NNP'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('San', 'NNP'),\n",
       " ('Francisco', 'NNP'),\n",
       " ('Bay', 'NNP'),\n",
       " ('Area', 'NNP'),\n",
       " ('making', 'VBG'),\n",
       " ('it', 'PRP'),\n",
       " ('the', 'DT'),\n",
       " ('second', 'JJ'),\n",
       " ('most', 'RBS'),\n",
       " ('densely', 'RB'),\n",
       " ('populated', 'JJ'),\n",
       " ('large', 'JJ'),\n",
       " ('U.S.', 'NNP'),\n",
       " ('city', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('fifth', 'NN'),\n",
       " ('most', 'RBS'),\n",
       " ('densely', 'RB'),\n",
       " ('populated', 'JJ'),\n",
       " ('U.S', 'NNP')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf.tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextBlob currently has two POS tagger implementations, located in textblob.taggers. The default is the\n",
    "PatternTagger which uses the same implementation as the pattern library.\n",
    "\n",
    "The second implementation is NLTKTagger which uses NLTK’s TreeBank tagger. Numpy is required to use the\n",
    "NLTKTagger.\n",
    "\n",
    "Similar to the tokenizers and noun phrase chunkers, you can explicitly specify which POS tagger to use by passing a\n",
    "tagger instance to the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Tag', 'NN'), ('You', 'PRP'), (\"'re\", 'VBP'), ('It', 'PRP')]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from textblob.taggers import NLTKTagger\n",
    "nltk_tagger = NLTKTagger()\n",
    "blob = TextBlob(\"Tag! You're It!\", pos_tagger=nltk_tagger)\n",
    "blob.pos_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Noun Phrase Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['san francisco', 'sf', 'san fran', 'frisco', 'financial center', 'california', 'san francisco', 'populous city', 'california', 'square miles', 'san francisco peninsula', 'san francisco', 'bay area', 'u.s.', 'u.s'])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf.noun_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextBlob currently has two noun phrases chunker implementations, textblob.np_extractors, FastNPExtractor\n",
    "\n",
    "np_extractors.ConllExtractor, which uses the CoNLL 2000 corpus to train a tagger.\n",
    "You can change the chunker implementation (or even use your own) by explicitly passing an instance of a noun phrase\n",
    "extractor to a TextBlob’s constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['python', 'high-level programming language'])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.np_extractors import ConllExtractor\n",
    "extractor = ConllExtractor()\n",
    "blob = TextBlob(\"Python is a high-level programming language.\", np_extractor=extractor)\n",
    "blob.noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The textblob.sentiments module contains two sentiment analysis implementations, PatternAnalyzer\n",
    "(based on the pattern library) and NaiveBayesAnalyzer (an NLTK classifier trained on a movie reviews corpus).\n",
    "\n",
    "The default implementation is PatternAnalyzer, but you can override the analyzer by passing another implemen-\n",
    "tation into a TextBlob’s constructor.\n",
    "\n",
    "For instance, the NaiveBayesAnalyzer returns\n",
    "Sentiment(classification, p_pos, p_neg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.39166666666666666, subjectivity=0.4357142857142857)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testimonial = TextBlob(\"Textblob is amazingly simple to use. What great fun!\")\n",
    "testimonial.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39166666666666666"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testimonial.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(classification='pos', p_pos=0.7996209910191279, p_neg=0.2003790089808724)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "blob = TextBlob(\"I love this library\", analyzer=NaiveBayesAnalyzer())\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenizarion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can break TextBlobs into words or sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['San', 'Francisco', 'officially', 'the', 'City', 'and', 'County', 'of', 'San', 'Francisco', 'and', 'colloquially', 'known', 'as', 'SF', 'San', 'Fran', 'Frisco', 'or', 'The', 'City', 'is', 'the', 'cultural', 'commercial', 'and', 'financial', 'center', 'of', 'Northern', 'California', 'San', 'Francisco', 'is', 'the', '16th', 'most', 'populous', 'city', 'in', 'the', 'United', 'States', 'and', 'the', 'fourth', 'most', 'populous', 'in', 'California', 'with', '881,549', 'residents', 'as', 'of', '2019.It', 'covers', 'an', 'area', 'of', 'about', '46.89', 'square', 'miles', '121.4', 'km2', 'mostly', 'at', 'the', 'north', 'end', 'of', 'the', 'San', 'Francisco', 'Peninsula', 'in', 'the', 'San', 'Francisco', 'Bay', 'Area', 'making', 'it', 'the', 'second', 'most', 'densely', 'populated', 'large', 'U.S', 'city', 'and', 'the', 'fifth', 'most', 'densely', 'populated', 'U.S'])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"San Francisco, officially the City and County of San Francisco and colloquially known as SF, San Fran, Frisco, or The City,is the cultural, commercial, and financial center of Northern California.\"),\n",
       " Sentence(\"San Francisco is the 16th most populous city in the United States, and the fourth most populous in California, with 881,549 residents as of 2019.It covers an area of about 46.89 square miles (121.4 km2),mostly at the north end of the San Francisco Peninsula in the San Francisco Bay Area, making it the second most densely populated large U.S. city, and the fifth most densely populated U.S.\")]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf.sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence objects have the same properties and methods as TextBlobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.0, subjectivity=0.05)\n",
      "Sentiment(polarity=0.3163265306122449, subjectivity=0.34693877551020413)\n"
     ]
    }
   ],
   "source": [
    "for sentence in sf.sentences:\n",
    "    print(sentence.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words and sentences properties are helpers that use the textblob.tokenizers.WordTokenizer\n",
    "and textblob.tokenizers.SentenceTokenizer classes, respectively.\n",
    "You can use other tokenizers, such as those provided by NLTK, by passing them into the TextBlob constructor then\n",
    "accessing the tokens property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['This is', 'a rather tabby', 'blob.'])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from nltk.tokenize import TabTokenizer\n",
    "tokenizer = TabTokenizer()\n",
    "blob = TextBlob(\"This is\\ta rather tabby\\tblob.\", tokenizer=tokenizer)\n",
    "blob.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Words Inflection and Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each word in TextBlob.words or Sentence.words is a Word object (a subclass of unicode) with useful\n",
    "methods, e.g. for word inflection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Use', '4', 'spaces', 'per', 'indentation', 'level'])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = TextBlob('Use 4 spaces per indentation level.')\n",
    "sentence.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'space'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words[2].singularize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'levels'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words[-1].pluralize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words can be lemmatized by calling the lemmatize method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'octopus'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "w = Word(\"octopi\")\n",
    "w.lemmatize()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = Word(\"went\")\n",
    "w.lemmatize(\"v\")# Pass in WordNet part of speech (verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tentacles of octopus prepared as food',\n",
       " 'bottom-living cephalopod having a soft oval body with eight long tentacles']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word(\"octopus\").definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WordLists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A WordList is just a Python list with additional methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['cat', 'dog', 'octopus'])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals = TextBlob(\"cat dog octopus\")\n",
    "animals.words\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['cats', 'dogs', 'octopodes'])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals.words.pluralize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spelling Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the correct() method to attempt spelling correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have good spelling!\n"
     ]
    }
   ],
   "source": [
    "b = TextBlob(\"I havv goood speling!\")\n",
    "print(b.correct())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word objects have a spellcheck() Word.spellcheck() method that returns a list of (word,\n",
    "confidence) tuples with spelling suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fallibility', 1.0)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = Word('falibility')\n",
    "w.spellcheck()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Word and Noun Phrase Frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to get the frequency of a word or noun phrase in a TextBlob.\n",
    "\n",
    "The first is through the word_counts dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty = TextBlob(\"We are no longer the Knights who say Ni. \"\n",
    "\"We are now the Knights who say Ekki ekki ekki PTANG.\")\n",
    "\n",
    "monty.word_counts['ekki']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you access the frequencies this way, the search will not be case sensitive, and words that are not found will have a\n",
    "frequency of 0.\n",
    "\n",
    "The second way is to use the count() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty.words.count('ekki', case_sensitive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf.noun_phrases.count('San Francisco')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the parse() method to parse the text.\n",
    "\n",
    "By default, TextBlob uses pattern’s parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And/CC/O/O now/RB/B-ADVP/O for/IN/B-PP/B-PNP something/NN/B-NP/I-PNP completely/RB/B-ADJP/O different/JJ/I-ADJP/O ././O/O\n"
     ]
    }
   ],
   "source": [
    "b = TextBlob(\"And now for something completely different.\")\n",
    "print(b.parse())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TextBlobs Are Like Python Strings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use Python’s substring syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"San Francisco, officially the City and County of San Francisco and colloquially known as SF, San Fran, Frisco, or The City,is the cultural, commercial, and financial center of Northern California. San\")"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf[0:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make comparisons between TextBlobs and strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_blob = TextBlob('apples')\n",
    "banana_blob = TextBlob('bananas')\n",
    "apple_blob < banana_blob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can concatenate and interpolate TextBlobs and strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"apples and bananas\")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_blob + ' and ' + banana_blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apples and bananas'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{0} and {1}\".format(apple_blob, banana_blob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TextBlob.ngrams() method returns a list of tuples of n successive words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(\"Now is better than never.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['Now', 'is', 'better']),\n",
       " WordList(['is', 'better', 'than']),\n",
       " WordList(['better', 'than', 'never'])]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.ngrams(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Start and End Indices of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "San Francisco, officially the City and County of San Francisco and colloquially known as SF, San Fran, Frisco, or The City,is the cultural, commercial, and financial center of Northern California.\n",
      "---- Starts at index 0, Ends at index 196\n",
      "San Francisco is the 16th most populous city in the United States, and the fourth most populous in California, with 881,549 residents as of 2019.It covers an area of about 46.89 square miles (121.4 km2),mostly at the north end of the San Francisco Peninsula in the San Francisco Bay Area, making it the second most densely populated large U.S. city, and the fifth most densely populated U.S.\n",
      "---- Starts at index 197, Ends at index 588\n"
     ]
    }
   ],
   "source": [
    "for s in sf.sentences:\n",
    "    print(s)\n",
    "    print(\"---- Starts at index {}, Ends at index {}\".format(s.start, s.end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a Text Classification System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [\n",
    "('I love this sandwich.', 'pos'),\n",
    "('this is an amazing place!', 'pos'),\n",
    "('I feel very good about these beers.', 'pos'),\n",
    "('this is my best work.', 'pos'),\n",
    "(\"what an awesome view\", 'pos'),\n",
    "('I do not like this restaurant', 'neg'),\n",
    "('I am tired of this stuff.', 'neg'),\n",
    "(\"I can't deal with this\", 'neg'),\n",
    "('he is my sworn enemy!', 'neg'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\n",
    "('the beer was good.', 'pos'),\n",
    "('I do not enjoy my job', 'neg'),\n",
    "(\"I ain't feeling dandy today.\", 'neg'),\n",
    "(\"I feel amazing!\", 'pos'),\n",
    "('Gary is a friend of mine.', 'pos'),\n",
    "(\"I can't believe I'm doing this.\", 'neg')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "cl = NaiveBayesClassifier(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also load data from common file formats including CSV, JSON, and TSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.json', 'r') as fp:\n",
    "    cl = NaiveBayesClassifier(fp, format=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.classify(\"This is an amazing library!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(prob_dist.prob(\"pos\"), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to classify text is to pass a classifier into the constructor of TextBlob and call its classify()\n",
    "method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "blob = TextBlob(\"I do not like this restaurant.I love this sandwich.\", classifier=cl)\n",
    "blob.classify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advantage of this approach is that you can classify sentences within a TextBlob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The beer is good.\n",
      "pos\n",
      "But the hangover is horrible.\n",
      "pos\n"
     ]
    }
   ],
   "source": [
    "for s in blob.sentences:\n",
    "    print(s)\n",
    "    print(s.classify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.accuracy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['This is', 'a rather tabby', 'blob.'])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from nltk.tokenize import TabTokenizer\n",
    "tokenizer = TabTokenizer()\n",
    "blob = TextBlob(\"This is\\ta rather tabby\\tblob.\", tokenizer=tokenizer)\n",
    "blob.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['python', 'high-level programming language'])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.np_extractors import ConllExtractor\n",
    "extractor = ConllExtractor()\n",
    "blob = TextBlob(\"Python is a high-level programming language.\", np_extractor=extractor)\n",
    "blob.noun_phrases\n",
    "#WordList(['python', 'high-level programming language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Tag', 'NN'), ('You', 'PRP'), (\"'re\", 'VBP'), ('It', 'PRP')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.taggers import NLTKTagger\n",
    "nltk_tagger = NLTKTagger()\n",
    "blob = TextBlob(\"Tag! You're It!\", pos_tagger=nltk_tagger)\n",
    "blob.pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

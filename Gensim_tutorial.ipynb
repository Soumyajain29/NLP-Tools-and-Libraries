{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gensim_tutorial",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1HEIrkOYux34dRyuLWrNN9tHG9tBaKNM_",
      "authorship_tag": "ABX9TyNvIVM2cxatg/2r8ZQExzYu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzr7-d0NF6eA",
        "colab_type": "text"
      },
      "source": [
        "# **Gensim = \"Generate Similar\"**\n",
        "Gensim is a Python library for topic modelling, document indexing and similarity retrieval with large corpora.\n",
        "\n",
        "**Features-**\n",
        "*   All algorithms are memory-independent w.r.t. the corpus size (can process input larger than RAM, streamed, out-of-core).\n",
        "*   Intuitive interfaces-\n",
        " *   Easy to plug in your own input corpus/datastream (simple streaming API)\n",
        " * Easy to extend with other Vector Space algorithms (simple transformation API)  \n",
        "*  Efficient multicore implementations of popular algorithms, such as online LSI, LDA, Random Projections (RP), Hierarchical Dirichlet Process (HDP) or word2vec deep learning.\n",
        "*   Distributed computing: can run LSA and LDA on a cluster of computers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGiiSZEf9Tks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "from pprint import pprint\n",
        "import spacy\n",
        "from gensim import corpora"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k9tTrNyCUAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_corpus = [\"The fox jumps over the dog\",\n",
        "              \"The fox is very clever and quick\",\n",
        "              \"The dog is slow and lazy\",\n",
        "              \"The cat is smarter than the fox and the dog\",\n",
        "              \"Python is an excellent programming language\",\n",
        "              \"Java and ruby are other programming languages\",\n",
        "              \"Python and Java are very popular programming languages\",\n",
        "              \"Python programmes are smaller than java programs\"]"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U2Ov2BeHIMK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "38f1d491-a932-4381-b685-a266786833b0"
      },
      "source": [
        "#pre-processing\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def preprocess(txt_corpus):\n",
        "  pp_corpus = []\n",
        "  for line in txt_corpus:\n",
        "    doc = nlp(line)\n",
        "    #Removing punctuations and stop words\n",
        "    pp_tokens = [token for token in doc if not (token.is_punct or token.is_stop)]\n",
        "    #Lemmatization\n",
        "    pp_corpus.append([token.lemma_ if token.lemma_.lower() is not '-PRON-' else token.lower() for token in pp_tokens])\n",
        "  return pp_corpus\n",
        "\n",
        "pp_corpus  = preprocess(text_corpus)\n",
        "pp_corpus"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['fox', 'jump', 'dog'],\n",
              " ['fox', 'clever', 'quick'],\n",
              " ['dog', 'slow', 'lazy'],\n",
              " ['cat', 'smart', 'fox', 'dog'],\n",
              " ['Python', 'excellent', 'programming', 'language'],\n",
              " ['Java', 'ruby', 'programming', 'language'],\n",
              " ['Python', 'Java', 'popular', 'programming', 'language'],\n",
              " ['Python', 'programme', 'small', 'java', 'program']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZGkKxK7VsVT",
        "colab_type": "text"
      },
      "source": [
        "**Bag of Words (BOW)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxHOmkgaUNyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dictionary = corpora.Dictionary(pp_corpus)\n",
        "bow_corpus = [dictionary.doc2bow(doc) for doc in pp_corpus]"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8czINRegUV2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "6f8e03f9-30f0-4417-ca11-2dfb9efc4d06"
      },
      "source": [
        "print(dictionary.token2id)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'dog': 0, 'fox': 1, 'jump': 2, 'clever': 3, 'quick': 4, 'lazy': 5, 'slow': 6, 'cat': 7, 'smart': 8, 'Python': 9, 'excellent': 10, 'language': 11, 'programming': 12, 'Java': 13, 'ruby': 14, 'popular': 15, 'java': 16, 'program': 17, 'programme': 18, 'small': 19}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ENhfMvcHbtw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "44598a7a-f3e4-4a4b-cdc7-d2a254824c6e"
      },
      "source": [
        "#To save memory, Gensim omits all vector elements with value 0.0\n",
        "bow_corpus"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, 1), (1, 1), (2, 1)],\n",
              " [(1, 1), (3, 1), (4, 1)],\n",
              " [(0, 1), (5, 1), (6, 1)],\n",
              " [(0, 1), (1, 1), (7, 1), (8, 1)],\n",
              " [(9, 1), (10, 1), (11, 1), (12, 1)],\n",
              " [(11, 1), (12, 1), (13, 1), (14, 1)],\n",
              " [(9, 1), (11, 1), (12, 1), (13, 1), (15, 1)],\n",
              " [(9, 1), (16, 1), (17, 1), (18, 1), (19, 1)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Dbr0XDIWhdZ",
        "colab_type": "text"
      },
      "source": [
        "**TF-IDF**\n",
        "\n",
        "Tf-idf stands for **term frequency-inverse document frequency**.\n",
        "This weight is a statistical measure used to evaluate how important a word is to a document in a collection or corpus. The importance increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus.\n",
        "\n",
        "Applications-\n",
        "\n",
        "\n",
        "*   Information Retrieval\n",
        "*   Keyword Extraction\n",
        "*   Stopwords filtering etc\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J3lyYpA46Fj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f7a1dd0e-a19f-4c91-84da-1cf91bb49787"
      },
      "source": [
        "from  gensim import models\n",
        "# Create the TF-IDF model\n",
        "tfidf = models.TfidfModel(bow_corpus,normalize=True)  #training\n",
        "tfidf"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.tfidfmodel.TfidfModel at 0x7f39ee66f780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPK8pu5BAFyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_tfidf = tfidf[bow_corpus] "
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0j3J_MnQKyTc",
        "colab_type": "text"
      },
      "source": [
        "*Note-*\n",
        "\n",
        "Calling model[corpus] only creates a wrapper around the old corpus document stream – actual conversions are done on-the-fly, during document iteration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnW0om6Ie9cc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "fda22189-37ff-4970-9ee5-a61110ea6f46"
      },
      "source": [
        "for doc in corpus_tfidf:\n",
        "    print(doc)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 0.39239043318859274), (1, 0.39239043318859274), (2, 0.8319011334792957)]\n",
            "[(1, 0.31639356562839216), (3, 0.6707813025230176), (4, 0.6707813025230176)]\n",
            "[(0, 0.31639356562839216), (5, 0.6707813025230176), (6, 0.6707813025230176)]\n",
            "[(0, 0.30165504678093485), (1, 0.30165504678093485), (7, 0.6395343874660627), (8, 0.6395343874660627)]\n",
            "[(9, 0.36527597081532565), (10, 0.7744161642390763), (11, 0.36527597081532565), (12, 0.36527597081532565)]\n",
            "[(11, 0.3431499531386567), (12, 0.3431499531386567), (13, 0.4850047483738612), (14, 0.7275071225607918)]\n",
            "[(9, 0.3245721388452534), (11, 0.3245721388452534), (12, 0.3245721388452534), (13, 0.4587470494748973), (15, 0.688120574212346)]\n",
            "[(9, 0.22954235351308377), (16, 0.4866493367774363), (17, 0.4866493367774363), (18, 0.4866493367774363), (19, 0.4866493367774363)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXuFM7iiIkcX",
        "colab_type": "text"
      },
      "source": [
        "# **Topic Models-**\n",
        "\n",
        "In machine learning and natural language processing, a topic model is a type of statistical model for discovering the abstract \"topics\" that occur in a collection of documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyqc3XuR-D0k",
        "colab_type": "text"
      },
      "source": [
        "**Latent Dirichlet allocation(LDA)**\n",
        "\n",
        "* In NLP, LDA is a generative statistical model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar.\n",
        "* For example, if observations are words collected into documents, it posits that each document is a mixture of a small number of topics and that each word's presence is attributable to one of the document's topics. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ9XjsQQavfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda_model = gensim.models.LdaModel(corpus_tfidf, \n",
        "                                   num_topics = 2, \n",
        "                                   id2word = dictionary.id2token,                                    \n",
        "                                   passes = 50,\n",
        "                                   per_word_topics = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-W2vCxxKmL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_topics = lda_model.top_topics(corpus_tfidf ,topn =5)"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8y4kPrVS8hm",
        "colab_type": "text"
      },
      "source": [
        "Topic Coherence-\n",
        "\n",
        "Topic Coherence is a measure used to evaluate topic models.\n",
        "Each such generated topic consists of words, and the topic coherence is applied to the top N words from the topic. It is defined as the average / median of the pairwise word-similarity scores of the words in the topic (e.g. PMI)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqUhkrs5SsK2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "8f2b69d1-6724-44cf-d985-989dfa0eb418"
      },
      "source": [
        "pprint(top_topics)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[([(0.07817043, 'programming'),\n",
            "   (0.07817026, 'language'),\n",
            "   (0.0735714, 'Java'),\n",
            "   (0.07235142, 'Python'),\n",
            "   (0.06485425, 'excellent')],\n",
            "  -3.1855571233754922),\n",
            " ([(0.09691611, 'fox'),\n",
            "   (0.08535472, 'jump'),\n",
            "   (0.085127614, 'dog'),\n",
            "   (0.074984066, 'quick'),\n",
            "   (0.07498405, 'clever')],\n",
            "  -10.810484484839957)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-Ixu5imSfxB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "231e4914-a355-460b-f77d-6bd48a0f6382"
      },
      "source": [
        "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
        "avg_topic_coherence = sum([t[1] for t in top_topics]) / 2\n",
        "print('Average topic coherence: %.4f.' % avg_topic_coherence)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average topic coherence: -6.9980.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_RJ23J8iOtg",
        "colab_type": "text"
      },
      "source": [
        "**Latent semantic indexing (LSI)**\n",
        "\n",
        "*   LSI is an indexing and retrieval method that uses SVD to identify patterns in the relationships between the terms and concepts contained in an unstructured collection of text.\n",
        "\n",
        "* LSI is based on the principle that words that are used in the same contexts tend to have similar meanings.\n",
        "\n",
        "* A key feature of LSI is its ability to extract the conceptual content of a body of text by establishing associations between those terms that occur in similar contexts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_DpZLasjVlj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import LsiModel\n",
        "\n",
        "#Here we transformed our Tf-Idf corpus via LSI into a latent 3-D space (3-D because we set num_topics=3)\n",
        "lsi_model = LsiModel(corpus_tfidf,id2word = dictionary, num_topics =3)  # train model"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBAbjoIyId2S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a656904b-145e-4448-9cd7-a46c25c7415e"
      },
      "source": [
        "vector = lsi_model[corpus_tfidf[5]]  # apply model to tfidf document\n",
        "vector"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 0.7452348915110869), (2, -0.24031610763830696)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkaJIfw6aUZj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "c837c6d3-cb57-4cfa-daf6-00634b323218"
      },
      "source": [
        "lsi_model.print_topics(3)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.449*\"programming\" + 0.449*\"language\" + 0.429*\"Java\" + 0.327*\"popular\" + 0.322*\"Python\" + 0.315*\"ruby\" + 0.308*\"excellent\" + 0.047*\"program\" + 0.047*\"java\" + 0.047*\"programme\"'),\n",
              " (1,\n",
              "  '0.459*\"fox\" + 0.459*\"dog\" + 0.444*\"jump\" + 0.322*\"cat\" + 0.322*\"smart\" + 0.208*\"slow\" + 0.208*\"lazy\" + 0.208*\"quick\" + 0.208*\"clever\" + 0.000*\"Java\"'),\n",
              " (2,\n",
              "  '0.468*\"small\" + 0.468*\"programme\" + 0.468*\"java\" + 0.468*\"program\" + 0.238*\"Python\" + -0.174*\"ruby\" + -0.142*\"Java\" + 0.075*\"excellent\" + -0.065*\"language\" + -0.065*\"programming\"')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvihxx0caVAz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "e0980b05-91f0-4955-d277-ff29646b7f2a"
      },
      "source": [
        "corpus_lsi = lsi_model[corpus_tfidf]  # create a double wrapper over the original corpus: bow->tfidf->fold-in-lsi\n",
        "for doc, as_text in zip(corpus_lsi, text_corpus):\n",
        "    print(doc, as_text)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(1, 0.729605340630538)] The fox jumps over the dog\n",
            "[(1, 0.42469706069369845)] The fox is very clever and quick\n",
            "[(1, 0.4246970606936987)] The dog is slow and lazy\n",
            "[(1, 0.689295072973576)] The cat is smarter than the fox and the dog\n",
            "[(0, 0.6839200687841975), (2, 0.09779960609472999)] Python is an excellent programming language\n",
            "[(0, 0.7452348915110869), (2, -0.24031610763830696)] Java and ruby are other programming languages\n",
            "[(0, 0.8174724665245316), (2, -0.05726191138435917)] Python and Java are very popular programming languages\n",
            "[(0, 0.16458343363665945), (2, 0.9661657160778017)] Python programmes are smaller than java programs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67jjQBTjCWxs",
        "colab_type": "text"
      },
      "source": [
        "# **Word2Vec Model-**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKVlKzfBIV0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PolP4ZIM1fZk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "e7d43763-b7ef-44f0-8246-8258df3aba39"
      },
      "source": [
        "!wget 'http://nlp.stanford.edu/data/glove.6B.zip' 'drive/My Drive'"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-21 14:45:37--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-07-21 14:45:37--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-07-21 14:45:38--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.01MB/s    in 8m 1s   \n",
            "\n",
            "2020-07-21 14:53:42 (1.71 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "--2020-07-21 14:53:42--  http://drive/My%20Drive\n",
            "Resolving drive (drive)... failed: No address associated with hostname.\n",
            "wget: unable to resolve host address ‘drive’\n",
            "FINISHED --2020-07-21 14:53:42--\n",
            "Total wall clock time: 8m 5s\n",
            "Downloaded: 1 files, 822M in 8m 1s (1.71 MB/s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEdSkHUGz7ks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"/content/glove.6B.zip\", 'r')\n",
        "zip_ref.extractall(\"drive/My Drive/\")\n",
        "zip_ref.close()"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej55I1M72Nyj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "a802c1d8-13db-43f6-8d32-bdd8f49b93b1"
      },
      "source": [
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "glove_file = datapath('/content/drive/My Drive/glove.6B.100d.txt')\n",
        "word2vec_glove_file = get_tmpfile(\"glove.6B.100d.word2vec.txt\")\n",
        "glove2word2vec(glove_file, word2vec_glove_file)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o82yiUv20We",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = KeyedVectors.load_word2vec_format(word2vec_glove_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmbFMgm_46q0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "0783c049-4722-4e64-da14-71c6ff90044b"
      },
      "source": [
        "model.most_similar('banana',topn=7)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('coconut', 0.7097253799438477),\n",
              " ('mango', 0.7054824233055115),\n",
              " ('bananas', 0.6887733936309814),\n",
              " ('potato', 0.6629636287689209),\n",
              " ('pineapple', 0.6534532904624939),\n",
              " ('fruit', 0.6519855260848999),\n",
              " ('peanut', 0.6420576572418213)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSzSiJWa29FV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "375b81ac-3357-41e6-c24f-d2a916ab6162"
      },
      "source": [
        "model.most_similar(negative= 'dog' ,topn=4)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('aquaculturists', 0.5666294097900391),\n",
              " ('oakleys', 0.5649899244308472),\n",
              " ('http://www.opel.com', 0.5606860518455505),\n",
              " ('ricefields', 0.5550658702850342)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztvv_5XD2_5h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "773a8152-ad14-4c0f-ee69-03d64428d79e"
      },
      "source": [
        "result = model.most_similar(positive=['woman', 'king'], negative=['man'])\n",
        "print(\"{}: {:.4f}\".format(*result[0]))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "queen: 0.7699\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hE5pNeq3Ayc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "1a41b38c-643c-4a07-876a-06034a459f12"
      },
      "source": [
        "def analogy(x1, x2, y1):\n",
        "    result = model.most_similar(positive=[y1, x2], negative=[x1])\n",
        "    return result[0][0]\n",
        "\n",
        "analogy('japan', 'japanese', 'australia')"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'australian'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s8Zdhj33Hyc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "b2112231-4771-44df-8fed-bbefaf95e8a7"
      },
      "source": [
        "print(model.doesnt_match(\"breakfast cereal dinner lunch\".split()))"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cereal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMNc0oTlvnhv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = ( \"Human machine interface for lab abc computer applications.\"\n",
        "                \"A survey of user opinion of computer system response time.\"\n",
        "                \"The EPS user interface management system.\"\n",
        "                \"System and human system engineering testing of EPS.\"\n",
        "                \"Relation of user perceived response time to error measurement.\"\n",
        "                \"The intersection graph of paths in trees.\"\n",
        "                \"Graph minors IV Widths of trees and well quasi ordering.\"\n",
        "                \"Graph minors a survey\")\n",
        "\n",
        "doc1 = nlp(corpus)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEhe0bWxMnjj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "c461a3ca-ec3c-4967-ada6-80cc9adb55a1"
      },
      "source": [
        "sentences = [str(sentence) for sentence in doc1.sents]\n",
        "sentences"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Human machine interface for lab abc computer applications.',\n",
              " 'A survey of user opinion of computer system response time.',\n",
              " 'The EPS user interface management system.',\n",
              " 'System and human system engineering testing of EPS.Relation of user perceived response time to error measurement.',\n",
              " 'The intersection graph of paths in trees.',\n",
              " 'Graph minors IV Widths of trees and well quasi ordering.',\n",
              " 'Graph minors a survey']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKmA5ONwM6xT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "abbdda04-8671-447b-c907-e74884da2d9a"
      },
      "source": [
        "tokenized_sentences = preprocess(sentences)\n",
        "print(tokenized_sentences)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['human', 'machine', 'interface', 'lab', 'abc', 'computer', 'application'], ['survey', 'user', 'opinion', 'computer', 'system', 'response', 'time'], ['EPS', 'user', 'interface', 'management', 'system'], ['system', 'human', 'system', 'engineering', 'testing', 'eps.relation', 'user', 'perceive', 'response', 'time', 'error', 'measurement'], ['intersection', 'graph', 'path', 'tree'], ['Graph', 'minor', 'IV', 'Widths', 'tree', 'quasi', 'ordering'], ['Graph', 'minor', 'survey']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9bB40R2LoL8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1b3396b7-eca3-4edd-eaf3-19cacab42aee"
      },
      "source": [
        "# instantiating and training the Word2Vec model\n",
        "model = gensim.models.Word2Vec(tokenized_sentences, min_count=1,window=5,size=100 , compute_loss=True,iter = 15)\n",
        "\n",
        "# getting the training loss value\n",
        "training_loss = model.get_latest_training_loss()\n",
        "training_loss"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "546.4014282226562"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N2m5JV3MFLU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "30f519a4-b9ff-4114-d8a7-159e5d4a389a"
      },
      "source": [
        "word_vec = model.wv['computer']\n",
        "word_vec"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-4.1612535e-04, -2.2380303e-03,  2.2937683e-03, -3.1812473e-03,\n",
              "        2.8154387e-03, -3.7848067e-03, -1.4736252e-04, -7.4351655e-04,\n",
              "        2.5403826e-03, -3.5814167e-04,  4.4296319e-03,  6.0696085e-04,\n",
              "        1.7392690e-03,  1.1080391e-03, -2.8571922e-03,  4.3057656e-04,\n",
              "        7.7703310e-04,  4.4810087e-03,  4.1730711e-03, -4.7920914e-03,\n",
              "       -4.2877247e-04,  2.8659985e-03,  8.2127699e-05,  9.3507167e-04,\n",
              "        2.7063708e-03,  4.6429560e-03,  1.8652041e-03,  3.3616212e-03,\n",
              "       -3.5358602e-03, -4.1404823e-03, -3.0854866e-03,  9.0099184e-04,\n",
              "       -4.7521577e-03, -3.2824520e-03,  6.3185004e-04,  2.6604035e-03,\n",
              "        4.3843249e-03, -6.5386965e-04,  4.4207289e-03, -2.4266243e-03,\n",
              "        5.6468189e-04, -3.3247694e-03,  3.8855260e-03, -2.6469135e-03,\n",
              "       -2.4846315e-03,  4.8967609e-03, -1.3287842e-03,  2.2864668e-03,\n",
              "       -3.8460798e-03, -8.0878247e-04, -6.9844187e-04,  3.8065044e-03,\n",
              "       -1.0497979e-04, -2.7236375e-03, -1.2956148e-03,  4.7890400e-03,\n",
              "        2.8876346e-03, -3.9895345e-03, -5.3590379e-04, -1.7985346e-03,\n",
              "       -8.4543385e-04, -3.1614676e-03, -3.9054237e-03, -1.6434826e-03,\n",
              "        4.1743689e-03, -4.2305714e-03,  1.1649546e-03, -3.2998370e-03,\n",
              "       -3.0151012e-04, -1.1931085e-03,  4.0177424e-03, -3.8150244e-03,\n",
              "       -2.2175164e-04, -1.9563185e-03,  3.2896115e-03, -4.7708363e-05,\n",
              "       -4.0032831e-03, -2.2665211e-03,  3.1568457e-03,  3.1018711e-04,\n",
              "       -2.8234473e-03,  1.6346266e-03, -3.7795985e-03, -4.1216691e-03,\n",
              "        7.3458266e-04,  4.5633889e-03,  4.7662230e-03, -4.0553380e-03,\n",
              "       -1.0454224e-04, -3.3428858e-03,  4.4944165e-03,  7.0710102e-04,\n",
              "       -5.3128554e-04, -1.5308852e-04,  2.5112827e-03, -2.4257272e-03,\n",
              "       -1.1868168e-03, -3.3424811e-03, -1.0857307e-03, -4.7340756e-03],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUJsmLOcJ8ut",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "a5209afb-ce94-4507-d3e2-3f4953a684fb"
      },
      "source": [
        "model.save('./w2v')\n",
        "model = gensim.models.Word2Vec.load('./w2v')"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAwK2Cd2QqDr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "62924952-360e-45b1-fa08-26d70832fa5c"
      },
      "source": [
        "more_sentences = [['how', 'are' ,'you'] , ['have','a','nice','day']]\n",
        "model.build_vocab(more_sentences, update=True)\n",
        "model.train(more_sentences, total_examples=model.corpus_count, epochs=5)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 35)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLo5qjTL3J4P",
        "colab_type": "text"
      },
      "source": [
        "# **Text Summarization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SewNgarAT_VM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.summarization import summarize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzBCwrnv2qbs",
        "colab_type": "text"
      },
      "source": [
        "* This module automatically summarizes the given text, by extracting one or more important sentences from the text.\n",
        "In a similar way, it can also extract keywords.\n",
        "\n",
        "* This summarizer is based on [ “TextRank” algorithm by Mihalcea et al.](https://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf).\n",
        "\n",
        "\n",
        "***Note-***\n",
        "Gensim’s summarization only works for English for now, because the text is pre-processed.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2w36xM20l_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = (\n",
        "    \"Thomas A. Anderson is a man living two lives. By day he is an \"\n",
        "    \"average computer programmer and by night a hacker known as \"\n",
        "    \"Neo. Neo has always questioned his reality, but the truth is \"\n",
        "    \"far beyond his imagination. Neo finds himself targeted by the \"\n",
        "    \"police when he is contacted by Morpheus, a legendary computer \"\n",
        "    \"hacker branded a terrorist by the government. Morpheus awakens \"\n",
        "    \"Neo to the real world, a ravaged wasteland where most of \"\n",
        "    \"humanity have been captured by a race of machines that live \"\n",
        "    \"off of the humans' body heat and electrochemical energy and \"\n",
        "    \"who imprison their minds within an artificial reality known as \"\n",
        "    \"the Matrix. As a rebel against the machines, Neo must return to \"\n",
        "    \"the Matrix and confront the agents: super-powerful computer \"\n",
        "    \"programs devoted to snuffing out Neo and the entire human \"\n",
        "    \"rebellion. \"\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jHE0GPL0tKA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "97f50be0-b3e5-44db-ff6d-28512a18df80"
      },
      "source": [
        "pprint(summarize(text, split=True , ratio = .4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['By day he is an average computer programmer and by night a hacker known as '\n",
            " 'Neo. Neo has always questioned his reality, but the truth is far beyond his '\n",
            " 'imagination.',\n",
            " 'Morpheus awakens Neo to the real world, a ravaged wasteland where most of '\n",
            " 'humanity have been captured by a race of machines that live off of the '\n",
            " \"humans' body heat and electrochemical energy and who imprison their minds \"\n",
            " 'within an artificial reality known as the Matrix.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fuoUKlz0xgD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "c16c69f0-a135-4816-f1ef-dc289ffd22d7"
      },
      "source": [
        "pprint(summarize(text, split=False , word_count=100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('By day he is an average computer programmer and by night a hacker known as '\n",
            " 'Neo. Neo has always questioned his reality, but the truth is far beyond his '\n",
            " 'imagination.\\n'\n",
            " 'Morpheus awakens Neo to the real world, a ravaged wasteland where most of '\n",
            " 'humanity have been captured by a race of machines that live off of the '\n",
            " \"humans' body heat and electrochemical energy and who imprison their minds \"\n",
            " 'within an artificial reality known as the Matrix.\\n'\n",
            " 'As a rebel against the machines, Neo must return to the Matrix and confront '\n",
            " 'the agents: super-powerful computer programs devoted to snuffing out Neo and '\n",
            " 'the entire human rebellion.')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-ZN3qr91I4V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "b455cc9e-fac6-4a56-fff4-e94c5e8d948e"
      },
      "source": [
        "from gensim.summarization import keywords\n",
        "print(keywords(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "humanity\n",
            "human\n",
            "neo\n",
            "humans body\n",
            "super\n",
            "hacker\n",
            "reality\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}